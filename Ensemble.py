import os
import gc
from utils.data_io import read_data_from_dataset
import pandas as pd
import matplotlib.pyplot as plt
import torch

from tqdm import tqdm # é¡¯ç¤ºé€²åº¦æ¢ï¼Œçœ‹åˆ°ä»»å‹™çš„å®Œæˆé€²åº¦ã€‚
import numpy as np
from utils.save import save_prediction_plot, save_yy_plot, save_mse, ResidualPlot, ErrorHistogram

from main import create_sliding_window # ä»£æ›¿èˆŠçš„ ReccurentPredictingGenerator
from utils.model import build_model # ç›´æ¥ç”¨ PyTorch æ¶æ§‹åˆå§‹åŒ–æ¨¡å‹ä¸¦è¼‰å…¥ .pt æ¬Šé‡ã€‚


def ensemble (sequence_length, write_out_dir, target):
    '''
    ensembleé›†æˆå¼å­¸ç¿’çš„é æ¸¬çµæœ
    '''
    print(f'\nç›®æ¨™è³‡æ–™é›†: {target}')
    write_result_out_dir = os.path.join(write_out_dir, target)
    print(f'Ensemble é æ¸¬è¼¸å‡ºè·¯å¾‘: {write_result_out_dir}')

    # === è®€å–æ¸¬è©¦è³‡æ–™ ===
    data_dir_path = os.path.join('.', 'dataset', 'target', target)
    _, _, X_test, y_test = read_data_from_dataset(data_dir_path)

    if not sequence_length:
        sequence_length = 1440 # periodï¼šè¡¨ç¤ºæ™‚é–“æ­¥æ•¸ï¼ˆtime stepsï¼‰ï¼Œå³æ¨¡å‹ä¸€æ¬¡çœ‹å¤šå°‘æ­¥çš„æ­·å²æ•¸æ“šä¾†é€²è¡Œé æ¸¬ã€‚ä¸‹æ¡æ¨£å¾Œå°‡è³‡æ–™é™ç‚ºæˆæ¯åˆ†é˜ä¸€å€‹æ•¸æ“šé»ï¼Œä»¥ 1 å¤© = 1440 åˆ†é˜é€²è¡Œè§€å¯Ÿã€‚
    print(f'ä½¿ç”¨æ™‚é–“æ­¥é•·ï¼ˆsequence_lengthï¼‰: {sequence_length}')

    # === å»ºç«‹æ»‘å‹•è¦–çª— ===
    X_test_seq, y_test_seq = create_sliding_window(X_test, y_test, sequence_length)
    X_test_tensor = torch.tensor(X_test_seq, dtype=torch.float32)
    test_dataset = torch.utils.data.TensorDataset(X_test_tensor)
    test_loader = torch.utils.data.DataLoader(
        test_dataset,
        batch_size=1, # ä¿æŒ batch=1ï¼Œå°±ç­‰åŒä»¥å‰çš„ RPG é€ç­†è™•ç†
        shuffle=False,
        pin_memory=True, # å°‡ DataLoader è¼‰å…¥çš„è³‡æ–™æ”¾åˆ°å›ºå®šçš„è¨˜æ†¶é«”ï¼ˆpinned memoryï¼‰ä¸­ï¼Œé€™æ¨£ è³‡æ–™èƒ½æ›´å¿«å‚³é€åˆ° GPUã€‚
        num_workers=0 # æ‰€æœ‰è³‡æ–™è®€å–åœ¨ ä¸»åŸ·è¡Œç·’ ä¸­å®Œæˆï¼ˆå–®åŸ·è¡Œç·’ï¼‰ã€æœ€å®‰å…¨ã€‘
    )

    # === å°æ¯å€‹æ¨¡å‹é€²è¡Œæ¨è«– ===
    prediction = [] # ç”¨æ–¼å­˜å„²æ¯å€‹æ¨¡å‹çš„é æ¸¬å€¼
    # åŠ è¼‰æ¨¡å‹ä¸¦ç”Ÿæˆé æ¸¬
    model_dir = os.path.join(write_result_out_dir, 'model')
    for model_file in tqdm(os.listdir(model_dir), desc='Loading Models'): # ç‚º model_dir è£¡çš„æ¯å€‹æ¨¡å‹æª”æ¡ˆå»ºç«‹ä¸€å€‹ tqdm é€²åº¦æ¢ï¼Œé¡¯ç¤ºæ–‡å­—ç‚º Loading Models
        model_path = os.path.join(model_dir, model_file)
        print(f'ä½¿ç”¨æ¨¡å‹: {target} ã® {model_file} \nè·¯å¾‘: {model_path}')

        # åˆå§‹åŒ–èˆ‡è¼‰å…¥æ¨¡å‹
        input_shape = (sequence_length, X_test.shape[1])
        model, device = build_model(input_shape=input_shape, gpu=True, verbose=False)
        model.load_state_dict(torch.load(model_path))
        model.eval()

        # é æ¸¬
        y_test_pred = []
        with torch.no_grad():
            for (x_batch,) in test_loader: # test_loader => ä½¿ç”¨ PyTorch çš„ DataLoader é€ç­†æ¨è«–ï¼Œç¯€çœè¨˜æ†¶é«”
                x_batch = x_batch.to(device)
                pred = model(x_batch)
                y_test_pred.append(pred.cpu().numpy())
        y_test_pred = np.concatenate(y_test_pred, axis=0)
        prediction.append(y_test_pred)

        # æ‰‹å‹•æ¸…ç†æ¨¡å‹ä»¥é‡‹æ”¾é¡¯å­˜
        del model
        torch.cuda.empty_cache()
        gc.collect()

    # === é›†æˆå¹³å‡ ===
    # è¨ˆç®—é æ¸¬çµæœçš„æº–ç¢ºåº¦ï¼Œä¸¦ä¿å­˜æ‰€æœ‰çš„é æ¸¬æ•¸æ“šã€‚é›†æˆæ‰€æœ‰é æ¸¬çµæœã€‚
    prediction = np.array(prediction) # è½‰æ›ç‚ºNumPyé™£åˆ—ï¼Œå½¢ç‹€ç‚º (æ¨¡å‹æ•¸é‡, æ¸¬è©¦æ•¸æ“šå¤§å°, é æ¸¬ç‰¹å¾µæ•¸=1)ã€‚ # å–®è®Šé‡é æ¸¬çµæœ
    print(f'\næ‰€æœ‰æ¨¡å‹é æ¸¬ shape: {prediction.shape}') # prediction shape: (æ¨¡å‹æ•¸é‡, æ¸¬è©¦æ¨£æœ¬æ•¸, 1)
    mean_pred = prediction.squeeze() # # å»æ‰æœ€å¾Œä¸€å€‹ç¶­åº¦ã€‚EX.å°‡æ•¸æ“šå½¢ç‹€å¾ (3, 31942, 1) è½‰ç‚º (3, 31942)
    mean_pred = np.mean(mean_pred, axis=0) # å°æ¯è¡Œæ•¸æ“šå–å¹³å‡å€¼ä½œç‚ºé›†æˆé æ¸¬çµæœï¼Œå³é›†æˆé æ¸¬å€¼ã€‚ # (n_samples,)

    y_test = y_test_seq # === ç¢ºä¿ ground truth å°é½Š ===   # ??
    # size_test = prediction.shape[1] # æ¸¬è©¦æ•¸æ“šçš„æ¨£æœ¬æ•¸é‡ã€‚
    # y_test[-size_test:] # å°‡y_testä¿®æ­£ç‚ºèˆ‡size_testé•·åº¦ç›¸åŒï¼Œç¢ºä¿æ¸¬è©¦æ¨™ç±¤èˆ‡é æ¸¬æ•¸æ“šå°é½Šã€‚
    print(f'y_test.shape: {y_test.shape}, pred.shape: {mean_pred.shape}') # èˆ‡y_testçš„å½¢ç‹€ä¸€è‡´
        
    # å°‡é æ¸¬è¼¸å‡ºå½™ç¸½æˆCSVä¿å­˜ # === ä¿å­˜å„æ¨¡å‹é æ¸¬ & å¹³å‡å€¼ ===
    df = pd.DataFrame() # çµ„åˆæ‰€æœ‰é æ¸¬çµæœç‚º DataFrame
    for i in range(prediction.shape[0]):
        df[f'Prediction_{i+1}'] = prediction[i].flatten() # å°‡æ¯ä¸€çµ„é æ¸¬çµæœå±•å¹³ç‚ºä¸€åˆ—
    df['Average'] = mean_pred # é æ¸¬å¹³å‡å€¼
    df.to_csv( os.path.join(write_result_out_dir, 'combined_predictions.csv'), index=False) # ä¿å­˜åˆ°åŒä¸€å€‹CSVæ–‡ä»¶            
    np.save( os.path.join(write_result_out_dir, f'{target}_ensemble_pred.npy'), prediction) # å°‡æ‰€æœ‰çš„é æ¸¬çµæœä¿å­˜ç‚ºNumPyæª”æ¡ˆ(.npy)ï¼Œå¯ç”¨np.loadè®€å–è³‡æ–™ã€‚

    # è¨ˆç®—é æ¸¬èª¤å·® # === è©•ä¼°èˆ‡ç¹ªåœ– ===
    mse_score, rmse_loss, mae_loss, mape_loss, msle_loss, r2 = save_mse(y_test, mean_pred, write_result_out_dir) # è¨ˆç®—y_testå’Œmean_predä¹‹é–“çš„å‡æ–¹èª¤å·®ï¼ˆMSEï¼‰åˆ†æ•¸ï¼ŒåŒæ™‚å°‡æ¨¡å‹æ‘˜è¦è³‡è¨Šå¯«å…¥æ–‡ä»¶ã€‚
    # ç¹ªè£½åœ–è¡¨
    plt.rcParams['font.size'] = 25 # è¨­å®šå­—é«”å¤§å°
    plt.figure(figsize=(15, 7)) # å»ºç«‹åœ–è¡¨
    save_prediction_plot(y_test, mean_pred, write_result_out_dir) # ç¹ªè£½y_testèˆ‡mean_predçš„å°æ¯”åœ–ï¼Œå±•ç¤ºé æ¸¬å€¼èˆ‡å¯¦éš›å€¼çš„åå·® (æŠ˜ç·šåœ–)
    save_yy_plot(y_test, mean_pred, write_result_out_dir) # ç¹ªè£½y_testèˆ‡mean_predçš„å°æ¯”åœ–ï¼Œå±•ç¤ºé æ¸¬å€¼èˆ‡å¯¦éš›å€¼çš„åå·® (æ•£é»åœ–)
    ResidualPlot(y_test, mean_pred, write_result_out_dir)
    ErrorHistogram(y_test, mean_pred, write_result_out_dir)
    print(f'\nâœ… é›†æˆé æ¸¬å®Œæˆï¼MSE: {mse_score:.4f}, MAE: {mae_loss:.4f}, RÂ²: {r2:.4f}\n')


def start_ensemble (sequence_length, write_out_dir):
    folders = [f for f in os.listdir(write_out_dir) if os.path.isdir(os.path.join(write_out_dir, f))]
    for target in folders:
        ensemble (sequence_length, write_out_dir, target)
        torch.cuda.empty_cache()
        gc.collect()
        print('\n' * 2 + '-' * 140 + '\n' * 2)
    print('âœ… Ensemble Learning å…¨éƒ¨çµæŸ ğŸ‰')